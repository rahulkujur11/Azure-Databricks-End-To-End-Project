ğŸ”¥ Azure Databricks End-to-End Project

ğŸ“š Overview
This is a comprehensive data engineering pipeline built using Azure Databricks, Delta Lake, and PySpark. It demonstrates real-world data transformation scenarios, including Slowly Changing Dimensions (SCD) management and star schema modeling. Ideal for learning or showcasing advanced data engineering workflows on the cloud.

ğŸ§° Tech Stack
List the major technologies and tools involved:
âœ… Azure Databricks
âœ… Delta Lake Gen2
âœ… Delta Live Tables (DLT)
âœ… PySpark
âœ… Azure Data Lake Storage
âœ… Power BI
âœ… Security/Access Management

ğŸ“Š Architecture Diagram
![image](https://github.com/user-attachments/assets/485c8964-e1a7-428c-bdb3-d2425b9a38cb)

âš™ï¸ Project Workflow
âœ… Data Ingestion from Azure/GitHub secured via role-based access.
âœ… ETL Process using Databricks and Delta Lake Gen2.
âœ… Transformations via PySpark and Delta Live Tables.
âœ… Modeling into a Star Schema.
âœ… Data Load into a Warehouse.
âœ… Reporting Layer using Power BI.

ğŸ” Key Concepts Implemented
âœ… Dimensional Data Modeling
âœ… Slowly Changing Dimensions (SCD Type 1, 2, etc.)
âœ… Delta Lake Transactions
âœ… Streaming with Spark
âœ… CI/CD via GitHub


ğŸ“ˆ Power BI Dashboard



