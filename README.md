🔥 Azure Databricks End-to-End Project

📚 Overview
This is a comprehensive data engineering pipeline built using Azure Databricks, Delta Lake, and PySpark. It demonstrates real-world data transformation scenarios, including Slowly Changing Dimensions (SCD) management and star schema modeling. Ideal for learning or showcasing advanced data engineering workflows on the cloud.

🧰 Tech Stack
List the major technologies and tools involved:
✅ Azure Databricks
✅ Delta Lake Gen2
✅ Delta Live Tables (DLT)
✅ PySpark
✅ Azure Data Lake Storage
✅ Power BI
✅ Security/Access Management

📊 Architecture Diagram
![image](https://github.com/user-attachments/assets/485c8964-e1a7-428c-bdb3-d2425b9a38cb)

⚙️ Project Workflow
✅ Data Ingestion from Azure/GitHub secured via role-based access.
✅ ETL Process using Databricks and Delta Lake Gen2.
✅ Transformations via PySpark and Delta Live Tables.
✅ Modeling into a Star Schema.
✅ Data Load into a Warehouse.
✅ Reporting Layer using Power BI.

🔍 Key Concepts Implemented
✅ Dimensional Data Modeling
✅ Slowly Changing Dimensions (SCD Type 1, 2, etc.)
✅ Delta Lake Transactions
✅ Streaming with Spark
✅ CI/CD via GitHub


📈 Power BI Dashboard



