# ðŸ”¥ Azure Databricks End-to-End Data Engineering Project

## ðŸ“š Overview

This project demonstrates a complete real-time data engineering pipeline using **Azure Databricks**, **Delta Lake**, and **PySpark**. It covers end-to-end data transformation scenarios including **Slowly Changing Dimensions (SCD)**, **Star Schema Modeling**, and **real-time streaming** â€” ideal for both learning and showcasing production-grade pipelines in the cloud.

---

## ðŸ§° Tech Stack

- âœ… Azure Databricks
- âœ… Delta Lake Gen2
- âœ… Delta Live Tables (DLT)
- âœ… PySpark
- âœ… Azure Data Lake Storage (ADLS)
- âœ… Power BI
- âœ… Role-Based Security and Access Control

---

## ðŸ§± Architecture

![Azure Project](https://github.com/user-attachments/assets/58d6a722-c7e1-4cbd-a661-267ba9bbe7b9)

---

## ðŸ”„ Pipeline Stages

1. **ðŸ” Data Ingestion**  
   - Source: Azure / GitHub  
   - Access: Secured via role-based access control (RBAC)

2. **âš™ï¸ ETL & Transformation**  
   - Tool: Databricks with Delta Lake Gen2  
   - Code: PySpark notebooks  
   - Real-time and batch pipelines using Delta Live Tables

3. **ðŸ“Š Data Modeling**  
   - Star schema with fact and dimension tables  
   - SCD Type 1 & Type 2 logic

4. **ðŸ¦ Data Load & Storage**  
   - Cleaned and modeled data stored in a curated (silver/gold) zone  
   - Delta Lake ensures ACID transactions and schema evolution

5. **ðŸ“ˆ Reporting Layer**  
   - Power BI dashboard built over final curated tables  
   - Real-time insights using DirectQuery or import mode

---

## ðŸš€ Features Implemented

- âœ… Real-time data streaming with Spark
- âœ… Dimensional modeling (Star Schema)
- âœ… SCD Type 1 and Type 2 implementation
- âœ… Delta Lake transactions & time travel
- âœ… Power BI integration
- âœ… CI/CD with GitHub version control

---

## ðŸ” Sample Pipeline View

![Databricks Pipeline](https://github.com/user-attachments/assets/e65105ac-6ee9-4a9a-b130-cf519b7d3312)

---

## ðŸ–¥ï¸ Power BI Dashboard

> *(Include a screenshot or link to Power BI dashboard once published)*

---

## ðŸ§ª How to Run

1. Clone the repository and open it in Azure Databricks.
2. Configure access to your Azure Data Lake and set required secrets.
3. Run notebooks in the provided order or trigger the DLT pipeline.
4. Load final tables into Power BI for dashboarding.

---


---

## ðŸ“¬ Feedback

Have suggestions or found a bug? Open an issue or create a pull request â€” all contributions are welcome!

---

## ðŸ“„ License

This project is licensed under the MIT License.


